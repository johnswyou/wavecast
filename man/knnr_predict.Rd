% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ddm.R
\name{knnr_predict}
\alias{knnr_predict}
\title{Predict using a K-Nearest Neighbors (KNN) regression model}
\usage{
knnr_predict(Y, X, Xtest, k = 3, method = "kd_tree")
}
\arguments{
\item{Y}{target vector (response variable) [N x 1]}

\item{X}{input matrix (explanatory variables) [N x D]}

\item{Xtest}{test input matrix for generating predictions [Ntest x D]}

\item{k}{number of nearest neighbours to use in prediction [scalar < N]}

\item{method}{\code{c("kd_tree", "cover_tree", "CR", "brute")}, Default: \code{"kd_tree"}}
}
\value{
prediction for input matrix Xtest [Ntest x 1]
}
\description{
This function calculates predictions for a set of model inputs 'Xtest'
using a k nearest neighbour model whose neighbour searching algorithm can
be selected according to different methods. The prediction is calculated
by assuming equally weighted predictions based on the k nearest neighbors.
}
\details{
The cover tree is O(n) space data structure which allows us to
answer queries in the same O(log(n)) time as kd tree given a
fixed intrinsic dimensionality. Templated code from
http://hunch.net/~jl/projects/cover_tree/cover_tree.html is used.
The kd tree algorithm is implemented in the Approximate Near
Neighbor (ANN) C++ library (see http://www.cs.umd.edu/~mount/ANN/).
The exact nearest neighbors are searched in this package.
The CR algorithm is the VR using distance 1-x'y assuming x and y
are unit vectors. The brute algorithm searches linearly. It is a
naive method.
}
\references{
Lall, U., and A. Sharma (1996), A nearest neighbor bootstrap for time series
resampling, Water. Resour. Res., 32, 679-693.
}
